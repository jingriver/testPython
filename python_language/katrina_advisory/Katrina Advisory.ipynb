{
 "metadata": {
  "difficulty": "intermediate",
  "duration": "average",
  "exercise_number": 3,
  "flavor": "general",
  "language": "english",
  "level": "real-life",
  "module": "PyFund_string",
  "name": "",
  "pre_requisites": [
   "PyFund_string",
   "header",
   "(PyFund_FileIO)",
   "(PyFund_control)"
  ],
  "programming_goals": [],
  "python_goals": [
   "string methods"
  ],
  "signature": "sha256:b9602dec7873e8bc54e64541b3878bbdd0398612f1376784c94cec298109f266"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "canopy_exercise": {
       "cell_type": "question"
      }
     },
     "source": [
      "Katrina Advisory Exercise\n",
      "=========================\n",
      "\n",
      "Whenever there's a Hurricane spinning out in the Atlantic (or Pacific), the US National Oceanic and Atomospheric Administration ([NOAA](http://www.noaa.gov/)) issues advisories about the storm's strength.  In this example, we will look at one such advisory for infamous [Hurricane Katrina](http://en.wikipedia.org/wiki/Hurricane_Katrina) that did so much damage to New Orleans in 2005.  \n",
      "\n",
      "Imagine you would like to build an application that \"reads\" storm advisories and assigns a danger level without human interaction.  There are a lot of tools that could help with this (like [NLTK](http://www.nltk.org/)) with fancy-dancy algorithms, but we're going to take a very simple approach of scanning the document for mincing words.\n",
      "\n",
      "Unlike a few of the other string exercises, the text for this example is located in a file on disk.  We haven't gotten to reading and writing files yet, but that is ok.  The following snippet of code opens the file \"katrina_advisory.txt\" (which is located in the same directory as this exercise), and dumps its contents into a string called `text`.  From here on out, you can work with `text` just as if you created the string yourself."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "f = open(\"katrina_advisory.txt\")\n",
      "text = f.read()\n",
      "f.close()\n",
      "print 'Content of \"katrina_advisory.txt\"'\n",
      "print '-' * 51\n",
      "print\n",
      "print text"
     ],
     "language": "python",
     "metadata": {
      "canopy_exercise": {
       "cell_type": "starting code"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "canopy_exercise": {
       "cell_type": "question"
      }
     },
     "source": [
      "Question 1\n",
      "----------\n",
      "Text and data processing always starts by some clean up. Format the text by converting it to lower case, remove spaces before and \n",
      "after the content. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Your code goes here!"
     ],
     "language": "python",
     "metadata": {
      "canopy_exercise": {
       "cell_type": "solution"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "canopy_exercise": {
       "cell_type": "question"
      }
     },
     "source": [
      "Question 2\n",
      "----------\n",
      "Ok.  Now for our own fancy-dancy algorithm.  Let's count the number of alarming terms in total in the processed `text`. For our purposes, we'll consider the following terms as alarming: \"killed\", \"destroyed\", \"death\", \"devastating\". (They all seem fairly alarming to me...)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Your code goes here!"
     ],
     "language": "python",
     "metadata": {
      "canopy_exercise": {
       "cell_type": "solution"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "canopy_exercise": {
       "cell_type": "question"
      }
     },
     "source": [
      "Question 3\n",
      "----------\n",
      "Let's also track how urgent NOAA thought the message was.  For this, we'll see if they started the message with the word \"URGENT\" (or \"urgent\").  Make a variable called `is_urgent` that is `True` if \"urgent\" is the first word and `False` otherwise.  As a hint, look at the methods available on strings.  At least one of them will be stunningly useful for our purposes..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Your code goes here!"
     ],
     "language": "python",
     "metadata": {
      "canopy_exercise": {
       "cell_type": "solution"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "canopy_exercise": {
       "cell_type": "question"
      }
     },
     "source": [
      "Question 4\n",
      "----------\n",
      "Now, let's compute an \"alarming words ratio\" as the number of alarming terms divided by the total number of words.\n",
      "\n",
      "The total number of words can be computed by splitting the string in individual words, then using the command `len` on the resulting list of words. \n",
      "\n",
      "Print the ratio with a precision of 3 decimal digits."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Your code goes here!"
     ],
     "language": "python",
     "metadata": {
      "canopy_exercise": {
       "cell_type": "solution"
      }
     },
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}