{
 "metadata": {
  "name": "",
  "signature": "sha256:fdd56a527e022145b47169656537d40a670e044afcbeb8933c43c210b9460d32"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Sentiment analysis exercise"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have been hired by the White House to analyze the image of President Obama in social media. As part of this effort, we would like to analyze the stream of tweets and rank them by how positive they are for the Obama administration.\n",
      "\n",
      "Sociologists have provided us with a list of \"positive\" and \"negative\" terms that we can use to compute a positivity and negativity index:\n",
      "\n",
      "  `positivity index = number of positive words / number of words`\n",
      "\n",
      "1. Execute the code below to download the list of positive and negative terms, and the tweets [1];\n",
      "2. Create a new list, containing a \"cleaned\" version of the tweets:\n",
      "   remove puncuation, and transform to lower case;\n",
      "3. For each tweet, count the number of positive and negative words in the sentence, and compute the positivity and negativity index.\n",
      "\n",
      "Bonus:\n",
      "\n",
      "4. Measure how much time is needed to complete the sentiment analysis on all tweets, using the `time.time()` function. Think about the performance of data type operations, and estimate how the key operations scale with number of tweets and number of sentiment terms. An efficient implementation should take a fraction of a second, can you improve your solution?\n",
      "\n",
      "[1] The sentiment word data has been released by Theresa Wilson, Janyce Wiebe, and Paul Hoffmann at the University of Pittsburgh, and processed by Neal Caren\n",
      "See http://nealcaren.web.unc.edu/an-introduction-to-text-analysis-with-python-part-3/ for details."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from time import time\n",
      "import urllib2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Download the positive terms.\n",
      "response = urllib2.urlopen('http://www.unc.edu/~ncaren/haphazard/positive.txt')\n",
      "positive_words = [word.strip() for word in response]\n",
      "print positive_words[::100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Download the negative terms.\n",
      "response = urllib2.urlopen('http://www.unc.edu/~ncaren/haphazard/negative.txt')\n",
      "negative_words = [word.strip() for word in response]\n",
      "print negative_words[::100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Download a list of tweets about President Obama\n",
      "response = urllib2.urlopen('http://www.unc.edu/~ncaren/haphazard/obama_tweets.txt')\n",
      "tweets = [tweet.strip() for tweet in response]\n",
      "print 'Number of tweets:', len(tweets)\n",
      "for tweet in tweets[::200]:\n",
      "    print '-', tweet"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start_time = time()\n",
      "# Your code goes here!\n",
      "stop_time = time()\n",
      "print 'Elapsed', stop_time-start_time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}